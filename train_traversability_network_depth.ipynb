{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from models.resnet_depth_unet import ResnetDepthUnet\n",
    "from utils.dataloader import TraversabilityDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "\n",
    "params = Object()\n",
    "# dataset parameters\n",
    "params.data_path        = r'data'\n",
    "params.csv_path         = os.path.join(params.data_path, 'data.csv')\n",
    "params.preproc          = True  # Vertical flip augmentation\n",
    "params.depth_mean       = 3.5235\n",
    "params.depth_std        = 10.6645\n",
    "\n",
    "# training parameters\n",
    "params.seed             = 230\n",
    "params.epochs           = 50\n",
    "params.batch_size       = 16\n",
    "params.learning_rate    = 1e-4\n",
    "params.weight_decay     = 1e-5\n",
    "\n",
    "# model parameters\n",
    "params.pretrained = True\n",
    "params.load_network_path = None \n",
    "params.input_size       = (424, 240)\n",
    "params.output_size      = (424, 240)\n",
    "params.output_channels  = 1\n",
    "params.bottleneck_dim   = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(params.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(params.seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResnetDepthUnet(params)\n",
    "\n",
    "# use to load a previously trained network\n",
    "if params.load_network_path is not None:\n",
    "    print('Loading saved network from {}'.format(params.load_network_path))\n",
    "    net.load_state_dict(torch.load(params.load_network_path))\n",
    "\n",
    "print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "net = torch.nn.DataParallel(net).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = net(torch.rand([2, 3, params.input_size[1], params.input_size[0]]).to(device), torch.rand([2, 1, params.input_size[1], params.input_size[0]]).to(device))\n",
    "print('test.shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "\n",
    "dataset = TraversabilityDataset(params, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, val_size = int(0.8*len(dataset)), np.ceil(0.2*len(dataset)).astype('int')\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader    = DataLoader(train_dataset, batch_size=params.batch_size, shuffle=True, num_workers=2)\n",
    "test_loader     = DataLoader(val_dataset, batch_size=params.batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "print('Total loaded %d images' % len(dataset))\n",
    "print('Loaded %d train images' % train_size)\n",
    "print('Loaded %d valid images' % val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss(reduction='none')\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=params.learning_rate, weight_decay=params.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in trange(params.epochs, desc='Training'):\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "     \n",
    "    for i, data in tenumerate(train_loader, desc='Inner'):\n",
    "        data = (item.to(device).type(torch.float32) for item in data)\n",
    "        color_img, depth_img, path_img, mu_img, nu_img, weight = data\n",
    "\n",
    "        pred = net(color_img, depth_img)\n",
    "\n",
    "        label = mu_img\n",
    "\n",
    "        loss = weight*criterion(pred*path_img, label)\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_list.append(train_loss)\n",
    "        \n",
    "    if (epoch) % 10 == 0:\n",
    "        tqdm.write(f'Epoch [{epoch+1}/{params.epochs}], Loss: {train_loss}')\n",
    "        tqdm.write(f'Learning Rate for this epoch: {optimizer.param_groups[0][\"lr\"]}')\n",
    "    \n",
    "    # evaluate the network on the test data\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        net.eval()\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = (item.to(device).type(torch.float32) for item in data)\n",
    "            color_img, depth_img, path_img, mu_img, nu_img, weight = data\n",
    "\n",
    "            pred = net(color_img, depth_img)\n",
    "\n",
    "            label = mu_img\n",
    "\n",
    "            loss = weight*criterion(pred*path_img, label)\n",
    "            loss = torch.mean(loss)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(test_loader)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        plt.figure(figsize = (14,14))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(color_img[0].permute(1, 2, 0).cpu().numpy())\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(255*pred[0,0,:,:].detach().cpu().numpy(), vmin=0, vmax=255)\n",
    "        plt.show(block=False)\n",
    "    \n",
    "    if best_val_loss > val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        tqdm.write(f'Updating best validation loss: {best_val_loss}')\n",
    "        torch.save(net.module.state_dict(),'checkpoints/best_predictor_depth.pth')\n",
    "\n",
    "    torch.save(net.module.state_dict(),'checkpoints/predictor_depth.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wayfast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:45:29) \n[GCC 10.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aecfa0b03dbf866f41383d0abce362e9950466e2b6c61c1c7af52f62961d4b42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
